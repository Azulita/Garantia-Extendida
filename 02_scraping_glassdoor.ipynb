{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Azulita/Garantia-Extendida/blob/master/02_scraping_glassdoor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdfd05da",
      "metadata": {
        "id": "fdfd05da"
      },
      "source": [
        "# Introducción\n",
        "\n",
        "Usaremos este notebook para hacer web scraping para encontrar nuestro trabajo ideal. La página de Glassdoor ofrece un catálogo de vacantes en diferentes empresas y nos gustaría poder descargar toda la información para poder analizarla después.\n",
        "\n",
        "Escribamos un código en Python para descargar toda la información que podamos y que lo podamos ejecutar en distintas ocasiones para actualizar nuestros datos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e8bf478",
      "metadata": {
        "id": "6e8bf478"
      },
      "source": [
        "Empecemos por instalar algunas librerías en caso de no tenerlas. Estas librerías nos servirán para replicar el comportamiento de un navegador (necesario en algunas páginas para que podamos extraer el código HTML) y para manipular el código HTML de una página y extraer información valiosa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47553d68",
      "metadata": {
        "id": "47553d68"
      },
      "outputs": [],
      "source": [
        "# !pip install beautifulsoup4\n",
        "# !pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "765ee0b4",
      "metadata": {
        "id": "765ee0b4"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import time\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73eae7d0",
      "metadata": {
        "id": "73eae7d0"
      },
      "source": [
        "Una vez instaladas las librerías, hagamos una consulta a una página de Glassdoor. En este caso, la URL se consiguió entrando a la página misma de Glassdoor, realizando una búsqueda y copiando la URL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f7023c1",
      "metadata": {
        "id": "3f7023c1"
      },
      "outputs": [],
      "source": [
        "# Genera un \"driver\", replicando a Google Chrome\n",
        "browser = webdriver.Chrome()\n",
        "\n",
        "# Realiza una consulta GET para obtener el código HTML\n",
        "browser.get(\"https://www.glassdoor.com.mx/Empleo/data-analyst-empleos-SRCH_KO0,12.htm\")\n",
        "\n",
        "# Obtiene el código fuente de la consulta GET\n",
        "html = browser.page_source\n",
        "time.sleep(2)\n",
        "\n",
        "# Cierra el navegador\n",
        "browser.close()\n",
        "\n",
        "# Análisis gramatical del código HTML\n",
        "soup = BeautifulSoup(html)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "000fef54",
      "metadata": {
        "id": "000fef54"
      },
      "source": [
        "# Web scraping"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b002602b",
      "metadata": {
        "id": "b002602b"
      },
      "source": [
        "Ahora, pasamos a extraer información valiosa del código HTML de la página. Extraeremos la información más valiosa, la iremos guardando primero en listas y después guardaremos la información en un DataFrame de Pandas al final."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5a9d713",
      "metadata": {
        "id": "d5a9d713"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "company_names = []\n",
        "company_ratings = []\n",
        "job_titles = []\n",
        "job_links = []\n",
        "job_ids = []\n",
        "locations = []\n",
        "salary_ranges = []\n",
        "is_fast_candidacies = []\n",
        "listing_ages = []\n",
        "\n",
        "job_cards = soup.find_all(\"li\", attrs={\"class\": \"JobsList_jobListItem__JBBUV\"})\n",
        "\n",
        "for job in job_cards:\n",
        "\n",
        "    company_info = job.find(\"div\", attrs={\"class\": \"EmployerProfile_employerInfo__GaPbq\"})\n",
        "\n",
        "    try:\n",
        "        company_rating_info = company_info.find(\"span\", attrs={\"class\": \"EmployerProfile_employerRating__3ADTJ\"})\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "    company_name = company_info.find_next(text=True)\n",
        "    try:\n",
        "        company_rating = company_rating_info.text.strip()\n",
        "    except:\n",
        "        company_rating = None\n",
        "\n",
        "    job_title_info = job.find(\"a\", attrs={\"class\": \"JobCard_seoLink__WdqHZ\"})\n",
        "    job_title = job_title_info.text\n",
        "    job_link = job_title_info.get(\"href\")\n",
        "    job_id = job_title_info.get(\"id\").replace(\"job-title-\", \"\")\n",
        "\n",
        "    location = job.find(\"div\", attrs={\"class\": \"JobCard_location__N_iYE\"}).text\n",
        "\n",
        "    # Limpiar: calcular límite inferior y superior\n",
        "    salary_range_info = job.find(\"div\", attrs={\"class\": \"JobCard_salaryEstimate___m9kY\"})\n",
        "    try:\n",
        "        salary_range = salary_range_info.text.replace(\"(Est. del empleador)\", \"\").replace(\"\\xa0\", \"\").strip()\n",
        "    except:\n",
        "        salary_range = None\n",
        "\n",
        "    # Limpiar: cambiar a 0 o 1\n",
        "    try:\n",
        "        is_fast_candidacy = job.find(\"div\", attrs={\"class\": \"JobCard_easyApply___eIoB\"}).text\n",
        "    except:\n",
        "        is_fast_candidacy = None\n",
        "\n",
        "    # Limpiar: sustituir horas por días, cambiar todo a enteros\n",
        "    listing_age = job.find(\"div\", attrs={\"class\": \"JobCard_listingAge__KuaxZ\"}).text.replace(\"\\xa0d\", \"\")\n",
        "\n",
        "    company_names.append(company_name)\n",
        "    company_ratings.append(company_rating)\n",
        "    job_titles.append(job_title)\n",
        "    job_links.append(job_link)\n",
        "    job_ids.append(job_id)\n",
        "    locations.append(location)\n",
        "    salary_ranges.append(salary_range)\n",
        "    is_fast_candidacies.append(is_fast_candidacy)\n",
        "    listing_ages.append(listing_age)\n",
        "\n",
        "jobs_data = pd.DataFrame(data={\n",
        "    \"company_name\": company_names,\n",
        "    \"company_rating\": company_ratings,\n",
        "    \"job_title\": job_titles,\n",
        "    \"job_link\": job_links,\n",
        "    \"job_id\": job_ids,\n",
        "    \"location\": locations,\n",
        "    \"salary_range\": salary_ranges,\n",
        "    \"is_fast_candidacy\": is_fast_candidacies,\n",
        "    \"listing_age\": listing_ages,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e4f859c",
      "metadata": {
        "id": "9e4f859c"
      },
      "outputs": [],
      "source": [
        "jobs_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b53ad3bf",
      "metadata": {
        "id": "b53ad3bf"
      },
      "source": [
        "## Sanity Checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5654437",
      "metadata": {
        "id": "d5654437"
      },
      "outputs": [],
      "source": [
        "jobs_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "022a1dcb",
      "metadata": {
        "id": "022a1dcb"
      },
      "outputs": [],
      "source": [
        "jobs_data[\"company_rating\"].astype(\"float\").mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41224bb8",
      "metadata": {
        "id": "41224bb8"
      },
      "outputs": [],
      "source": [
        "(jobs_data[\"is_fast_candidacy\"] == \"Candidatura rápida\").mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "910c36a8",
      "metadata": {
        "id": "910c36a8"
      },
      "source": [
        "# Guardar los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0abf8af",
      "metadata": {
        "id": "a0abf8af"
      },
      "outputs": [],
      "source": [
        "from datetime import date\n",
        "\n",
        "today = str(date.today())[:10]\n",
        "\n",
        "jobs_data.to_csv(f\"{today}_jobs_data.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feaa40e4",
      "metadata": {
        "id": "feaa40e4"
      },
      "source": [
        "# Tarea\n",
        "\n",
        "Existe un botón de `\"Mostrar más empleos\"` en la página consultada. Usando Selenium, repliquen el evento de dar click en ese botón para que aparezcan más resultados y vuelvan a extraer la información una vez que hayan logrado esto. Deberán de obtener una tabla con los 30 resultados de antes más resultados nuevos (aproximadamente otros 30 resultados)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed06dd58",
      "metadata": {
        "id": "ed06dd58"
      },
      "outputs": [],
      "source": [
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "\n",
        "browser = webdriver.Chrome()\n",
        "\n",
        "## 1. Obtener el código HTML incial\n",
        "browser.get(\"https://www.glassdoor.com.mx/Empleo/data-analyst-empleos-SRCH_KO0,12.htm\")\n",
        "\n",
        "## 2. instrucción para esperar a que cargue el botón que queremos\n",
        "time.sleep(5)\n",
        "selector = '//button[@data-test=\"load-more\"]'\n",
        "\n",
        "wait = WebDriverWait(browser, 10)\n",
        "button = wait.until(EC.element_to_be_clickable((By.XPATH, selector)))\n",
        "time.sleep(2)\n",
        "button.click()\n",
        "\n",
        "## 3. extraer el código HTML de la página después de haber dado click\n",
        "time.sleep(5)\n",
        "html = browser.page_source\n",
        "time.sleep(2)\n",
        "\n",
        "browser.close()\n",
        "\n",
        "soup = BeautifulSoup(html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41078fae",
      "metadata": {
        "id": "41078fae"
      },
      "outputs": [],
      "source": [
        "job_cards = soup.find_all(\"li\", attrs={\"class\": \"JobsList_jobListItem__JBBUV\"})\n",
        "len(job_cards)\n",
        "\n",
        "# Tiene que salir este resultado: 60 o 61"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7de2942e",
      "metadata": {
        "id": "7de2942e"
      },
      "source": [
        "Ahora, copien y peguen las instrucciones para extraer la información de la página y verifiquen que tienen más de 30 filas en su DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e546826b",
      "metadata": {
        "id": "e546826b"
      },
      "outputs": [],
      "source": [
        "# Copien y peguen el código de la sección \"Web Scraping\" aquí:\n",
        "# -------------------------- TAREA --------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d01ddcc",
      "metadata": {
        "id": "8d01ddcc"
      },
      "outputs": [],
      "source": [
        "jobs_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd4b368d",
      "metadata": {
        "id": "cd4b368d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}